<!doctype html><html lang=en><head><meta charset=utf-8><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=referrer content="no-referrer"><meta name=description content="I am trying to compute multiple loss gradients efficiently (without a for loop) in PyTorch. Given: The following works, but uses a for loop: For efficiency, I tried using torch.vmap instead: I was expecting it to compute the gradients of the losses w.r.t. the parameters for each element in x, y. Instead, I get an"><meta name=robots content="index,follow,noarchive"><link href="https://fonts.googleapis.com/css?family=Open+Sans:400|Old+Standard+TT:400&display=swap" rel=stylesheet media=print type=text/css onload='this.media="all"'><title>How do I compute multiple per-sample gradients efficiently?</title><link rel=canonical href=./how-do-i-compute-multiple-per-sample-gradients-efficiently.html><style>*{border:0;font:inherit;font-size:100%;vertical-align:baseline;margin:0;padding:0;color:#000;text-decoration-skip:ink}body{font-family:open sans,myriad pro,Myriad,sans-serif;font-size:17px;line-height:160%;color:#1d1313;max-width:700px;margin:auto}p{margin:20px 0}a img{border:none}img{margin:10px auto;max-width:100%;display:block}.left-justify{float:left}.right-justify{float:right}pre,code{font:12px Consolas,liberation mono,Menlo,Courier,monospace;background-color:#f7f7f7}code{font-size:12px;padding:4px}pre{margin-top:0;margin-bottom:16px;word-wrap:normal;padding:16px;overflow:auto;font-size:85%;line-height:1.45}pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:0 0;border:0}pre code{display:inline;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}pre code::before,pre code::after{content:normal}em,q,em,dfn{font-style:italic}.sans,html .gist .gist-file .gist-meta{font-family:open sans,myriad pro,Myriad,sans-serif}.mono,pre,code,tt,p code,li code{font-family:Menlo,Monaco,andale mono,lucida console,courier new,monospace}.heading,.serif,h1,h2,h3{font-family:old standard tt,serif}strong{font-weight:600}q:before{content:"\201C"}q:after{content:"\201D"}del,s{text-decoration:line-through}blockquote{font-family:old standard tt,serif;text-align:center;padding:50px}blockquote p{display:inline-block;font-style:italic}blockquote:before,blockquote:after{font-family:old standard tt,serif;content:'\201C';font-size:35px;color:#403c3b}blockquote:after{content:'\201D'}hr{width:40%;height:1px;background:#403c3b;margin:25px auto}h1{font-size:35px}h2{font-size:28px}h3{font-size:22px;margin-top:18px}h1 a,h2 a,h3 a{text-decoration:none}h1,h2{margin-top:28px}#sub-header,.date{color:#403c3b;font-size:13px}#sub-header{margin:0 4px}#nav h1 a{font-size:35px;color:#1d1313;line-height:120%}.posts_listing a,#nav a{text-decoration:none}li{margin-left:20px}ul li{margin-left:5px}ul li{list-style-type:none}ul li:before{content:"\00BB \0020"}#nav ul li:before,.posts_listing li:before{content:'';margin-right:0}#content{text-align:left;width:100%;font-size:15px;padding:60px 0 80px}#content h1,#content h2{margin-bottom:5px}#content h2{font-size:25px}#content .entry-content{margin-top:15px}#content .date{margin-left:3px}#content h1{font-size:30px}.highlight{margin:10px 0}.posts_listing{margin:0 0 50px}.posts_listing li{margin:0 0 25px 15px}.posts_listing li a:hover,#nav a:hover{text-decoration:underline}#nav{text-align:center;position:static;margin-top:60px}#nav ul{display:table;margin:8px auto 0}#nav li{list-style-type:none;display:table-cell;font-size:15px;padding:0 20px}#links{display:flex;justify-content:space-between;margin:50px 0 0}#links :nth-child(1){margin-right:.5em}#links :nth-child(2){margin-left:.5em}#not-found{text-align:center}#not-found a{font-family:old standard tt,serif;font-size:200px;text-decoration:none;display:inline-block;padding-top:225px}@media(max-width:750px){body{padding-left:20px;padding-right:20px}#nav h1 a{font-size:28px}#nav li{font-size:13px;padding:0 15px}#content{margin-top:0;padding-top:50px;font-size:14px}#content h1{font-size:25px}#content h2{font-size:22px}.posts_listing li div{font-size:12px}}@media(max-width:400px){body{padding-left:20px;padding-right:20px}#nav h1 a{font-size:22px}#nav li{font-size:12px;padding:0 10px}#content{margin-top:0;padding-top:20px;font-size:12px}#content h1{font-size:20px}#content h2{font-size:18px}.posts_listing li div{font-size:12px}}@media(prefers-color-scheme:dark){*,#nav h1 a{color:#fdfdfd}body{background:#121212}pre,code{background-color:#262626}#sub-header,.date{color:#bababa}hr{background:#ebebeb}}</style></head><body><section id=nav><h1><a href=./index.html>PicoDash</a></h1><ul><li><a href=./index.xml>Rss</a></li><li><a href=./sitemap.xml>Sitemap</a></li></ul></section><section id=content><h1>How do I compute multiple per-sample gradients efficiently?</h1><div id=sub-header>July 2024 Â· 2 minute read</div><div class=entry-content><img src=https://cdn.statically.io/img/cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><p>I am trying to compute multiple loss gradients efficiently (without a for loop) in PyTorch. Given:</p><pre class="lang-py prettyprint-override"><code>import torch from torch import nn class NeuralNetwork(nn.Module): def __init__(self): super().__init__() self.linear = nn.Sequential( nn.Linear(input_size, 16, bias=False), nn.Linear(16, output_size, bias=False), ) def forward(self, x): return self.linear(x) device = "cpu" input_size = 2 output_size = 2 x = torch.randn(10, 1, input_size).to(device) y = torch.randn(10, 1, output_size).to(device) model = NeuralNetwork().to(device) loss_fn = nn.MSELoss() def loss_grad(x, label): y = model(x) loss = loss_fn(y, label) grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True) return grads </code></pre><p>The following works, but uses a for loop:</p><pre><code># inefficient but works def compute_for(): grads = [loss_grad(x[i], y[i]) for i in range(x.shape[0])] print(grads) compute_for() </code></pre><p>For efficiency, I tried using <code>torch.vmap</code> instead:</p><pre><code># potentially more efficient but doesn't work def compute_vmap(): grads = torch.vmap(loss_grad)(x, y) print(grads) compute_vmap() </code></pre><p>I was expecting it to compute the gradients of the losses w.r.t. the parameters for each element in <code>x, y</code>. Instead, I get an error:</p><pre><code>RuntimeError: element 0 of tensors does not require grad </code></pre><p>As I understand, this means that elements from the tensor <code>x</code> will be computed and they don't individually require grad.</p><p>How can I modify this code so that it computes all gradients? Or is there another method to do that?</p><span class=d-none itemprop=commentCount>3</span><h2 class=mb0 data-answercount=1>1 Answer</h2><p>The per-sample gradients may be computed using <code>vmap</code> as shown in the relevant <a href=# rel="nofollow noreferrer">tutorial</a>:</p><pre><code>from torch.func import functional_call, vmap, grad def compute_loss(params, buffers, sample, target): batch = sample.unsqueeze(0) targets = target.unsqueeze(0) predictions = functional_call(model, (params, buffers), (batch,)) loss = loss_fn(predictions, targets) return loss params = {k: v.detach() for k, v in model.named_parameters()} buffers = {k: v.detach() for k, v in model.named_buffers()} ft_compute_grad = grad(compute_loss) ft_compute_sample_grad = vmap(ft_compute_grad, in_dims=(None, None, 0, 0)) ft_per_sample_grads = ft_compute_sample_grad(params, buffers, x, y) print(ft_per_sample_grads) </code></pre><p>These match the gradients computed individually for each pair <code>(x[i], y[i])</code>.</p><span class=d-none itemprop=commentCount></span><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmirpJawrLvVnqmfpJ%2Bse6S7zGiorp2jqbawutJobm9rZWiCdYKOoaawZZSkeqp5wqikqa2kmnquwcutoKmklWK9pr6MrJimqJyaeqi%2BwJ2gnqakqHqmssWimqKdnqm5ug%3D%3D</p></div><div id=links><a href=./professor-green-and-millie-mackintosh-split.html>&#171;&nbsp;Professor Green and Millie Mackintosh Announce Separation</a>
<a href=./siena-agudong.html>Sienna Agudong Relationship, Affair, Dating, Boyfriend, Net Worth&nbsp;&#187;</a></div></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>